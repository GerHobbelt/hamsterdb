/*
 * Copyright (C) 2005-2010 Christoph Rupp (chris@crupp.de).
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License as published by the
 * Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * See files COPYING.* for License information.
 */

/**
* @cond ham_internals
*/

/**
 * @brief implementation of the cache manager
 *
 */

#include "internal_preparation.h"




//#define CACHE_PURGE_THRESHOLD  (450 * 1024 * 1024) /* 500 mb */

#if 0
#define CACHE_BUCKET_SIZE    10313 /* 10317 is not prime ;) */
#define CACHE_MAX_ELEM       8192 /**< a power of 2 *below* CACHE_BUCKET_SIZE */
#endif

#define my_calc_hash(cache, o)                                              \
    ((ham_size_t)(cache_get_max_elements(cache)==0                          \
        ? 0                                                                 \
        : ((o) % cache_get_bucketsize(cache))))

ham_cache_t *
cache_new(ham_env_t *env, ham_size_t max_size)
{
    ham_cache_t *cache;
    ham_size_t mem;
    ham_size_t buckets;
    ham_size_t max_elements;

	/*
	Dimension the hash table so that the number of items would fit in the hash table itself with low collision risk:

	This means the intended fill ratio should ideally not reach beyond 50%: assuming we have a table size which is prime
	(we'll come to that in a sec), as we use a modulo-based hash scheme, we can expect low collision rates, hence
	a hash performance very close to O(1).

	The prime value should therefor be >= 2 * max_size.

	See http://mathworld.wolfram.com/Prime-GeneratingPolynomial.html for hash polynomials.
	Testing reveals that the [Dress and Landreau (2002), Gupta (2006)] polynomial is most suited for it does not only have a large
	range (almost all those polynomials exhibit 'swinging output value' behaviour and we like to keep it simple so we're interested
	in the primes in the final upwards slope, so that we perform a simple binary search through the formula output values.

	For the given polynomial that range would be N=21..63, where the last few values are not prime. N>=64 has 32-bit signed integer
	arithmetic overflow in the calculation.

	Of course, we could just go and plonk those prime numbers in a lookup table in here and binary search a fitting number.
	So much for having fun! Sigh. :-)

	So, in the end, I just took the 57 primes generated by said polynomial, absolute-valued them and sorted them in ascending order,
	so we can bsearch the table. (The  primes are not filtered for equidistance or some other metric, BTW)
	*/
	static const ham_size_t primes[] =
	{
		383,
		1721,
		3733,
		3923,
		4259,
		5323,
		10181,
		12547,
		12659,
		19373,
		20611,
		23887,
		26539,
		27847,
		32687,
		33073,
		37571,
		53149,
		65993,
		70123,
		87977,
		106207,
		124351,
		134077,
		142019,
		158923,
		174907,
		189977,
		204331,
		218389,
		228581,
		232823,
		248587,
		266947,
		289511,
		318259,
		355049,
		355573,
		404267,
		467617,
		519643,
		549391,
		653879,
		729173,
		785923,
		950947,
		991127,
		1154987,
		1313701,
		1404721,
		1705829,
		1707499,
		2071373,
		2505127,
		3018307,
		3621251,
		4325119
	};
	int idx = (sizeof(primes) / sizeof(primes[0])) / 2;
	const int max_idx = (sizeof(primes) / sizeof(primes[0])) - 2;
	int probe_span = (idx + 1) / 2;
	ham_size_t searchval;

	ham_assert(max_size > 0, (0));

    max_elements = (max_size + env_get_pagesize(env) - 1) / env_get_pagesize(env);
#if 0
	if (max_elements == 0 || max_elements > CACHE_MAX_ELEM)
        max_elements = CACHE_MAX_ELEM;
#endif

	// upper bound so we will be sure to locate a suitable prime-length hash table size.
	if (max_elements > primes[max_idx + 1] / 2)
	{
		// not 'unlimited', but still PLENTY:
		max_elements = primes[max_idx + 1] / 2;
	}

	searchval = max_elements * 2;

	for (;;)
	{
		if (primes[idx] < searchval)
		{
			if (primes[idx + 1] >= searchval)
			{
				idx++;
				break;
			}
			idx += probe_span;
			if (idx > max_idx)
				idx = max_idx;
		}
		else
		{
			if (idx == 0)
				break;

			if (primes[idx - 1] < searchval)
			{
				break;
			}
			idx -= probe_span;
			ham_assert(idx >= 0, (0));
		}
		probe_span = (probe_span + 1) / 2;
	}
	buckets = primes[idx];
    ham_assert(buckets > 0, (0));
    mem = sizeof(ham_cache_t)+(buckets-1)*sizeof(void *);

    cache = (ham_cache_t *)allocator_calloc(env_get_allocator(env), mem);
    if (!cache) {
        //env_set_error(env, HAM_OUT_OF_MEMORY);
        return NULL;
    }
    cache_set_max_elements(cache, max_elements);
    cache_set_bucketsize(cache, buckets);
	/* a reasonable start value; value is related
     * to the increments applied to active cache pages: */
    cache->_timeslot = 7;

    return cache;
}

void
cache_delete(ham_env_t *env, ham_cache_t *cache)
{
    allocator_free(env_get_allocator(env), cache);
}

/**
 * Apparently we've hit a high water mark in the counting business and
 * now it's time to cut down those counts to create a bit of fresh
 * headroom.
 *
 * As higher counters represent something akin to a heady mix of young
 * and famous (stardom gets you higher numbers) we're going to do
 * something to age them all, while maintaining their relative ranking:
 *
 * Instead of subtracting a certain amount Z, which would positively
 * benefit the high & mighty (as their distance from the lower life
 * increases disproportionally then), we DIVIDE all counts by a certain
 * number M, so that all counters are scaled down to generate lots of
 * headroom while keeping the picking order as it is.
 *
 * We happen to know that the high water mark is something close to
 * 2^31 - 1K (the largest step up for any page), so we decide to divide
 * by 2^16 - that still leaves us an optimistic resolution of 1:2^16,
 * which is fine.
 */
void
cache_reduce_page_counts(ham_cache_t *cache)
{
    ham_page_t *page=cache_get_totallist(cache);
    while (page) {
        /* act on ALL pages, including the reference-counted ones.  */
        ham_u32_t count = page_get_cache_cntr(page);

        /* now scale by applying division: */
        count >>= 16;
        page_set_cache_cntr(page, count);

        /* and the next one, please, James. */
        page=page_get_next(page, PAGE_LIST_CACHED);
    }

    /* and cut down the timeslot value as well: */
    /*
     * to make sure the division by 2^16 keeps the timing counter
     * non-zero, we mix in a little value...
     */
    cache->_timeslot+=(1<<16)-1;
    cache->_timeslot>>=16;
}

ham_page_t *
cache_get_unused_page(ham_cache_t *cache)
{
    ham_page_t *page;
    ham_page_t *oldest;

    /* fetch a page from the garbagelist
     *
     * TODO
     * the garbage list is no longer in use and can be removed
     */
    page=cache_get_garbagelist(cache);
    if (page) {
        ham_assert(page_get_refcount(page)==0,
                ("page is in use and in garbage list"));
        cache_set_garbagelist(cache,
                page_list_remove(cache_get_garbagelist(cache),
                    PAGE_LIST_GARBAGE, page));

        cache_set_cur_elements(cache,
                cache_get_cur_elements(cache)-1);
        return (page);
    }

    /* get the chronologically oldest page */
    oldest=cache_get_totallist_tail(cache);
    if (!oldest)
        return (0);

    /* now iterate through all pages, starting from the oldest
     * (which is the tail of the "totallist", the list of ALL cached
     * pages) */
    page=oldest;
    do {
        /* pick the first unused page (with a refcount of 0) */
        if (page_get_refcount(page)==0)
            break;

        page=page_get_previous(page, PAGE_LIST_CACHED);
        ham_assert(page!=oldest, (0));
    } while (page && page!=oldest);

    if (!page)
        return (0);

    /* remove the page from the cache and return it */
    cache_remove_page(cache, page);

    return (page);
}

ham_page_t *
cache_get_page(ham_cache_t *cache, ham_offset_t address, ham_u32_t flags)
{
    ham_page_t *page;
    ham_size_t hash=__calc_hash(cache, address);

    page=cache_get_bucket(cache, hash);
    while (page) {
        if (page_get_self(page)==address)
            break;
        page=page_get_next(page, PAGE_LIST_BUCKET);
    }

    /* not found? then return */
    if (!page)
        return (0);

    /* otherwise remove the page from the cache */
    cache_remove_page(cache, page);

    /* if the flag NOREMOVE is set, then re-insert the page.
     *
     * The remove/insert trick causes the page to be inserted at the
     * head of the "totallist", and therefore it will automatically move
     * far away from the tail. And the pages at the tail are highest
     * candidates to be deleted when the cache is purged. */
    if (flags&CACHE_NOREMOVE)
        cache_put_page(cache, page);

    return (page);
}

void
cache_put_page(ham_cache_t *cache, ham_page_t *page)
{
    ham_size_t hash=__calc_hash(cache, page_get_self(page));

    ham_assert(page_get_pers(page), (0));

    /* first remove the page from the cache, if it's already cached
     *
     * we re-insert the page because we want to make sure that the
     * cache->_totallist_tail pointer is updated
     *
     * TODO
     * is this really required?
     */
    if (page_is_in_list(cache_get_totallist(cache), page, PAGE_LIST_CACHED))
        cache_remove_page(cache, page);

    /* now (re-)insert into the list of all cached pages, and increment
     * the counter */
    ham_assert(!page_is_in_list(cache_get_totallist(cache), page,
                PAGE_LIST_CACHED), (0));
    cache_set_totallist(cache,
            page_list_insert(cache_get_totallist(cache),
            PAGE_LIST_CACHED, page));


    cache_set_cur_elements(cache,
            cache_get_cur_elements(cache)+1);

    /*
     * insert it in the cache bucket
     * !!!
     * to avoid inserting the page twice, we first remove it from the
     * bucket
     */
    if (page_is_in_list(cache_get_bucket(cache, hash), page, PAGE_LIST_BUCKET))
    {
        cache_set_bucket(cache, hash, page_list_remove(cache_get_bucket(cache,
                    hash), PAGE_LIST_BUCKET, page));
    }
    ham_assert(!page_is_in_list(cache_get_bucket(cache, hash), page,
                PAGE_LIST_BUCKET), (0));
    cache_get_bucket(cache, hash)=
            page_list_insert(cache_get_bucket(cache,
                    hash), PAGE_LIST_BUCKET, page);

    /* is this the chronologically oldest page? then set the pointer */
    if (!cache_get_totallist_tail(cache))
        cache_set_totallist_tail(cache, page);

    ham_assert(cache_check_integrity(cache)==0, (0));
}

/**
 * in order to improve cache activity for access patterns such as
 * AAB.AAB. where a fetch at the '.' would rate both pages A and B as
 * high, we use a increment-counter approach which will cause page A to
 * be rated higher than page B over time as A is accessed/needed more
 * often.
 */
void
cache_update_page_access_counter(ham_page_t *page, ham_cache_t *cache,
                        ham_u32_t extra_bump)
{
    if (cache->_timeslot > 0xFFFFFFFFU - 1024 - extra_bump)
        cache_reduce_page_counts(cache);

    cache->_timeslot++;
    page_set_cache_cntr(page, cache->_timeslot + extra_bump);
}

void
cache_remove_page(ham_cache_t *cache, ham_page_t *page)
{
    ham_bool_t removed = HAM_FALSE;

    /* are we removing the chronologically oldest page? then
     * update the pointer with the next oldest page */
    if (cache_get_totallist_tail(cache)==page)
        cache_set_totallist_tail(cache,
                page_get_previous(page, PAGE_LIST_CACHED));

    /* remove the page from the cache bucket */
    if (page_get_self(page)) {
        ham_size_t hash=__calc_hash(cache, page_get_self(page));
        if (page_is_in_list(cache_get_bucket(cache, hash), page,
                PAGE_LIST_BUCKET)) {
            cache_set_bucket(cache, hash,
                    page_list_remove(cache_get_bucket(cache, hash),
                    PAGE_LIST_BUCKET, page));
        }
    }

    /* remove it from the list of all cached pages */
    if (page_is_in_list(cache_get_totallist(cache), page, PAGE_LIST_CACHED)) {
        cache_set_totallist(cache, page_list_remove(cache_get_totallist(cache),
                PAGE_LIST_CACHED, page));
        removed = HAM_TRUE;
    }

    /* remove it from the garbage list */
    if (page_is_in_list(cache_get_garbagelist(cache), page, PAGE_LIST_GARBAGE)){
        cache_set_garbagelist(cache,
                    page_list_remove(cache_get_garbagelist(cache),
                    PAGE_LIST_GARBAGE, page));
        removed = HAM_TRUE;
    }

    /* decrease the number of cached elements */
    if (removed)
        cache_set_cur_elements(cache, cache_get_cur_elements(cache)-1);

    ham_assert(cache_check_integrity(cache)==0, (0));
}



ham_status_t
cache_check_integrity(ham_cache_t *cache)
{
    ham_size_t elements=0;
    ham_page_t *head;
    ham_page_t *tail=cache_get_totallist_tail(cache);

    /* count the cached pages */
    head=cache_get_totallist(cache);
    while (head) {
        elements++;
        head=page_get_next(head, PAGE_LIST_CACHED);
    }
    head=cache_get_garbagelist(cache);
    while (head) {
        elements++;
        head=page_get_next(head, PAGE_LIST_GARBAGE);
    }

    /* did we count the correct numbers? */
    if (cache_get_cur_elements(cache)!=elements) {
        ham_trace(("cache's number of elements (%u) != actual number (%u)",
                cache_get_cur_elements(cache), elements));
        return (HAM_INTEGRITY_VIOLATED);
    }

    /* make sure that the totallist HEAD -> next -> TAIL is set correctly,
     * and that the TAIL is the chronologically oldest page */
    head=cache_get_totallist(cache);
    while (head) {
        if (tail && !page_get_next(head, PAGE_LIST_CACHED))
            ham_assert(head==tail, (0));
        head=page_get_next(head, PAGE_LIST_CACHED);
    }
    if (tail)
        ham_assert(page_get_next(tail, PAGE_LIST_CACHED)==0, (0));

    return HAM_SUCCESS;
}


/**
* @endcond
*/

