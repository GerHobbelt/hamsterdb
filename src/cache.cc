/*
 * Copyright (C) 2005-2010 Christoph Rupp (chris@crupp.de).
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License as published by the
 * Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * See files COPYING.* for License information.
 */

/**
<<<<<<< HEAD
=======
* @cond ham_internals
*/

/**
>>>>>>> flash-bang-grenade
 * @brief implementation of the cache manager
 *
 */

<<<<<<< HEAD
#include "config.h"

#include <string.h>

#include "cache.h"
#include "env.h"
#include "error.h"
#include "mem.h"
#include "page.h"
#include "changeset.h"


Cache::Cache(Environment *env, ham_u64_t capacity_bytes)
  : m_env(env), m_capacity(capacity_bytes), m_cur_elements(0), m_totallist(0),
    m_totallist_tail(0)
{
    if (m_capacity==0)
        m_capacity=HAM_DEFAULT_CACHESIZE;

    for (ham_size_t i=0; i<CACHE_BUCKET_SIZE; i++)
        m_buckets.push_back(0);
}

ham_status_t
Cache::check_integrity(void)
{
    ham_size_t elements=0;
    Page *head;
    Page *tail=m_totallist_tail;

    /* count the cached pages */
    head=m_totallist;
    while (head) {
        elements++;
        head=head->get_next(Page::LIST_CACHED);
    }

    /* did we count the correct numbers? */
    if (m_cur_elements!=elements) {
        ham_trace(("cache's number of elements (%u) != actual number (%u)",
                m_cur_elements, elements));
        return (HAM_INTEGRITY_VIOLATED);
    }

    /* make sure that the totallist HEAD -> next -> TAIL is set correctly,
     * and that the TAIL is the chronologically oldest page */
    head=m_totallist;
    while (head) {
        if (tail && !head->get_next(Page::LIST_CACHED))
            ham_assert(head==tail, (""));
        head=head->get_next(Page::LIST_CACHED);
    }
    if (tail)
        ham_assert(tail->get_next(Page::LIST_CACHED)==0, (""));

    return (0);
}

=======
#include "internal_preparation.h"





#define my_calc_hash(cache, o)                                              \
    ((ham_size_t)(cache_get_max_elements(cache)==0                          \
        ? 0                                                                 \
        : ((o) % cache_get_bucketsize(cache))))

ham_cache_t *
cache_new(ham_env_t *env, ham_size_t max_size)
{
    ham_cache_t *cache;
    ham_size_t mem;
    ham_size_t buckets;
    ham_size_t max_elements;

    /*
    Dimension the hash table so that the number of items would fit in the hash table itself with low collision risk:

    This means the intended fill ratio should ideally not reach beyond 50%: assuming we have a table size which is prime
    (we'll come to that in a sec), as we use a modulo-based hash scheme, we can expect low collision rates, hence
    a hash performance very close to O(1).

    The prime value should therefor be >= 2 * max_size.

    See http://mathworld.wolfram.com/Prime-GeneratingPolynomial.html for hash polynomials.
    Testing reveals that the [Dress and Landreau (2002), Gupta (2006)] polynomial is most suited for it does not only have a large
    range (almost all those polynomials exhibit 'swinging output value' behaviour and we like to keep it simple so we're interested
    in the primes in the final upwards slope, so that we perform a simple binary search through the formula output values.

    For the given polynomial that range would be N=21..63, where the last few values are not prime. N>=64 has 32-bit signed integer
    arithmetic overflow in the calculation.

    Of course, we could just go and plonk those prime numbers in a lookup table in here and binary search a fitting number.
    So much for having fun! Sigh. :-)

    So, in the end, I just took the 57 primes generated by said polynomial, absolute-valued them and sorted them in ascending order,
    so we can bsearch the table. (The  primes are not filtered for equidistance or some other metric, BTW)
    */
    static const ham_size_t primes[] =
    {
        383,
        1721,
        3733,
        3923,
        4259,
        5323,
        10181,
        12547,
        12659,
        19373,
        20611,
        23887,
        26539,
        27847,
        32687,
        33073,
        37571,
        53149,
        65993,
        70123,
        87977,
        106207,
        124351,
        134077,
        142019,
        158923,
        174907,
        189977,
        204331,
        218389,
        228581,
        232823,
        248587,
        266947,
        289511,
        318259,
        355049,
        355573,
        404267,
        467617,
        519643,
        549391,
        653879,
        729173,
        785923,
        950947,
        991127,
        1154987,
        1313701,
        1404721,
        1705829,
        1707499,
        2071373,
        2505127,
        3018307,
        3621251,
        4325119
    };
    int idx = (sizeof(primes) / sizeof(primes[0])) / 2;
    const int max_idx = (sizeof(primes) / sizeof(primes[0])) - 2;
    int probe_span = (idx + 1) / 2;
    ham_size_t searchval;

    ham_assert(max_size > 0, (0));

    max_elements = (max_size + env_get_pagesize(env) - 1) / env_get_pagesize(env);
#if 0
    if (max_elements == 0 || max_elements > CACHE_MAX_ELEM)
        max_elements = CACHE_MAX_ELEM;
#endif

    // upper bound so we will be sure to locate a suitable prime-length hash table size.
    if (max_elements > primes[max_idx + 1] / 2)
    {
        // not 'unlimited', but still PLENTY:
        max_elements = primes[max_idx + 1] / 2;
    }

    searchval = max_elements * 2;

    for (;;)
    {
        if (primes[idx] < searchval)
        {
            if (primes[idx + 1] >= searchval)
            {
                idx++;
                break;
            }
            idx += probe_span;
            if (idx > max_idx)
                idx = max_idx;
        }
        else
        {
            if (idx == 0)
                break;

            if (primes[idx - 1] < searchval)
            {
                break;
            }
            idx -= probe_span;
            ham_assert(idx >= 0, (0));
        }
        probe_span = (probe_span + 1) / 2;
    }
    buckets = primes[idx];
    ham_assert(buckets > 0, (0));
    mem = sizeof(ham_cache_t)+(buckets-1)*sizeof(void *);

    cache = (ham_cache_t *)allocator_calloc(env_get_allocator(env), mem);
    if (!cache) {
        //env_set_error(env, HAM_OUT_OF_MEMORY);
        return NULL;
    }
    cache_set_max_elements(cache, max_elements);
    cache_set_bucketsize(cache, buckets);
    /* any start value is fine; value is related
     * to the increments applied to active cache pages: */
    cache->_timeslot = 0;

    return cache;
}

void
cache_delete(ham_env_t *env, ham_cache_t *cache)
{
    allocator_free(env_get_allocator(env), cache);
}

void
cache_reset(ham_cache_t *cache)
{
    ham_size_t elem_count = cache_get_bucketsize(cache);

    cache_set_cur_elements(cache, 0);

    memset(cache->_buckets, 0, sizeof(cache->_buckets[0]) * elem_count);
}


ham_page_t *
cache_get_unused_page(ham_cache_t *cache, ham_bool_t fast)
{
    ham_page_t *page;
    ham_page_t *head;
    ham_page_t *sentinel;
    ham_page_t *minp = NULL;
    ham_size_t hash;
    ham_s32_t max_age = HAM_MIN_S32;
    ham_s32_t min_freq;

    head = cache_get_totallist(cache);
    if (!head)
        return NULL;

    /*
     * Oh, this was all so unfair! <grin>
     *
     * As pages are added at the HEAD and NEXT for page P points to the
     * next older item (i.e. the previously added item to the linked
     * list), it means ->NEXT means 'older'.
     *
     * While, in finding the oldest, re-usable page, we should /start/
     * with the oldest and gradually progress towards the 'younger',
     * i.e. traverse the link list in reverse, by traversing the cyclic ->PREV chain
     * instead of the usual ->NEXT chain!
     *
     * Hence our 'proper' starting point then would be the
     * /probably oldest/ fella in the chain. /Probably oldest/ because there's
     * that bit of detail about access frequency, which will surely throw a spanner
     * in the works in this regard, as otherwise we can safely assume the timestamps
     * (page::_cache_cntr) are ordered from old to new when you start the linked
     * list traversal at HEAD->PREV and walk the ->PREV chain from there.
     *
     * As higher counters/frequencies represent something akin to a heady mix of young
     * and famous (stardom gets you higher numbers) we're going to do
     * something to find the antiquated pages which have seen little use:
     * As the timestamp-equivalent counters are updated with every page access,
     * we need the 'frequency' component to tell how important a page really is:
     * old pages which have high frequency counts though /were/ VIPs but not any
     * more! So a representative and simple-to-calculate age would be the
     * delta between the timestamp-counter and the current timestamp (lucky for
     * us we don't have to bother about possible integer overflow there as we'll be
     * performing signed integer arithmetic on that delta and we can safely
     * assume that any page will be 'antiquated' before the hamster went through
     * ~2E9 different pages! Furthermore, signed integer wrap-around we can handle sans probleme
     * when that would happen, so we're good to go). Anyway, we subtract
     * 'frequency' from the timestamp delta to get a representative 'age' number and
     * we then brutally retire our 'oldest, least useful' citizens first.
     * No pension fund for thou.
     *
     * In 'fast' mode we do NOT want to scan the entire list, so we apply a simple heuristic:
     *
     * We keep looking for older entries until we hit ANY entry which has an access frequency
     * LARGER than the current minimum frequency. This prevents us (on average) from scanning
     * both large series of 'live' pages when there are few 'free' nodes in between, and
     * we'll quit the search as soon as we've hit the first next 'younger' available page.
     *
     * When all pages have the same 'frequency', it means we'll only probe two 'free' pages
     * and pick the oldest (first one, nearest the tail end of the linked list).
     */
    sentinel = page = page_get_previous(head, PAGE_LIST_CACHED);
    min_freq = page_get_cache_hit_freq(page);
    ham_assert(page, ("cyclic linked list so always a valid PREV"));
    do
    {
        ham_s32_t freq_of_use = page_get_cache_hit_freq(page);

        /* only handle unused pages */
        if (page_get_refcount(page) == 0)
        {
            ham_s32_t age = cache->_timeslot - page_get_cache_cntr(page) - freq_of_use;

            if (age > max_age)
            {
                /* oldest! Further down chain at same age or has older age. */
                minp = page;
                max_age = age;
                if (min_freq > freq_of_use)
                    min_freq = freq_of_use;
            }
            else
            {
                ham_assert(minp, (0));
                if (fast)
                    break;
                else if (cache->_timeslot - page_get_cache_cntr(page) < max_age)
                {
                    /*
                    no use to look any further as the next pages in the list are guaranteed to be younger by 'counter/timestamp' alone,
                    which means that we won't be able to surpass the current best age metric with those.

                    Hence we stop the scan now, which incidentally speeds up these cache slot scans even when running in 'slow' mode! :-)
                    */
                    break;
                }
            }
        }
        else if (fast && minp)
        {
            if (min_freq >= freq_of_use)
                min_freq = freq_of_use;
            else
                break;
        }
        page = page_get_previous(page, PAGE_LIST_CACHED);
        ham_assert(page != NULL, (0));
    } while (page != sentinel);

    if (!minp)
        return NULL;

#if defined(HAM_DEBUG) && 00
    {
        ham_s32_t age = cache->_timeslot - page_get_cache_cntr(minp) - page_get_cache_hit_freq(minp);

        ham_trace(("ditching page with lowest counter: %d + %d vs. %d --> %d @ type: 0x%x / flags: 0x%x while HEAD = %d + %d\n",
            page_get_cache_cntr(minp), page_get_cache_hit_freq(minp), cache->_timeslot, age,
            (page_get_pers(minp) ? (unsigned)page_get_pers_type(minp) : 0),
            page_get_npers_flags(minp),
            page_get_cache_cntr(head), page_get_cache_hit_freq(head)));
    }
#endif

//found_page:
    hash = my_calc_hash(cache, page_get_self(minp));

    ham_assert(page_is_in_list(cache_get_totallist(cache), minp,
                    PAGE_LIST_CACHED), (0));
    cache_set_totallist(cache,
            page_list_remove(cache_get_totallist(cache),
            PAGE_LIST_CACHED, minp));
    ham_assert(page_is_in_list(cache_get_bucket(cache, hash), minp,
                    PAGE_LIST_BUCKET), (0));
    cache_set_bucket(cache, hash,
            page_list_remove(cache_get_bucket(cache,
            hash), PAGE_LIST_BUCKET, minp));

    cache_push_history(minp, -3);

    cache_set_cur_elements(cache,
            cache_get_cur_elements(cache)-1);

    return minp;
}

ham_page_t *
cache_get_page(ham_cache_t *cache, ham_offset_t address, ham_u32_t flags)
{
    ham_page_t *page;
    ham_size_t hash = my_calc_hash(cache, address);

    page=cache_get_bucket(cache, hash);
    while (page) {
        if (page_get_self(page)==address)
            break;
        page=page_get_next(page, PAGE_LIST_BUCKET);
    }

    if (page)
    {
        page_increment_cache_hit_freq(page);

        if ((flags & CACHE_NOREMOVE) == 0)
        {
            //ham_assert(page_is_in_list(cache_get_totallist(cache), page, PAGE_LIST_CACHED), (0));
            if (page_is_in_list(cache_get_totallist(cache), page, PAGE_LIST_CACHED))
            {
                cache_set_totallist(cache,
                    page_list_remove(cache_get_totallist(cache),
                    PAGE_LIST_CACHED, page));
            }
            ham_assert(page_is_in_list(cache_get_bucket(cache, hash), page,
                    PAGE_LIST_BUCKET), (0));
            cache_set_bucket(cache, hash,
                page_list_remove(cache_get_bucket(cache,
                hash), PAGE_LIST_BUCKET, page));

            cache_push_history(page, -4);

            cache_set_cur_elements(cache,
                cache_get_cur_elements(cache)-1);
        }
    }

    return (page);
}

ham_status_t
cache_put_page(ham_cache_t *cache, ham_page_t *page)
{
    ham_size_t hash = my_calc_hash(cache, page_get_self(page));
    ham_bool_t new_page = HAM_TRUE;

    ham_assert(page_get_pers(page), (0));

    if (page_is_in_list(cache_get_totallist(cache), page, PAGE_LIST_CACHED))
    {
        cache_set_totallist(cache,
                page_list_remove(cache_get_totallist(cache),
                PAGE_LIST_CACHED, page));

        new_page = HAM_FALSE;

        cache_set_cur_elements(cache,
                cache_get_cur_elements(cache)-1);
    }
    ham_assert(!page_is_in_list(cache_get_totallist(cache), page,
                PAGE_LIST_CACHED), (0));
    cache_set_totallist(cache,
            page_list_insert(cache_get_totallist(cache),
            PAGE_LIST_CACHED, page));

    cache_push_history(page, new_page ? +10 : 0);

    cache_set_cur_elements(cache,
            cache_get_cur_elements(cache)+1);

    /*
     * insert it in the cache bucket
     * !!!
     * to avoid inserting the page twice, we first remove it from the
     * bucket
     */
    //ham_assert(page_is_in_list(cache_get_bucket(cache, hash), page, PAGE_LIST_BUCKET), (0));
    if (page_is_in_list(cache_get_bucket(cache, hash), page, PAGE_LIST_BUCKET))
    {
        cache_set_bucket(cache, hash, page_list_remove(cache_get_bucket(cache,
                    hash), PAGE_LIST_BUCKET, page));
    }
    ham_assert(!page_is_in_list(cache_get_bucket(cache, hash), page,
                PAGE_LIST_BUCKET), (0));
    cache_set_bucket(cache, hash, page_list_insert(cache_get_bucket(cache,
                hash), PAGE_LIST_BUCKET, page));

    return HAM_SUCCESS;
}


ham_status_t
cache_remove_page(ham_cache_t *cache, ham_page_t *page)
{
    ham_bool_t removed = HAM_FALSE;

    if (page_get_self(page))
    {
        ham_size_t hash = my_calc_hash(cache, page_get_self(page));
        //ham_assert(page_is_in_list(cache_get_bucket(cache, hash), page, PAGE_LIST_BUCKET), (0));
        if (page_is_in_list(cache_get_bucket(cache, hash), page,
                PAGE_LIST_BUCKET))
        {
            cache_set_bucket(cache, hash,
                    page_list_remove(cache_get_bucket(cache, hash),
                    PAGE_LIST_BUCKET, page));
        }
    }

    if (page_is_in_list(cache_get_totallist(cache), page, PAGE_LIST_CACHED))
    {
        cache_set_totallist(cache, page_list_remove(cache_get_totallist(cache),
                PAGE_LIST_CACHED, page));
        removed = HAM_TRUE;
    }
    //ham_assert(removed, (0));
    if (removed) {
        cache_push_history(page, -1);

        cache_set_cur_elements(cache,
                cache_get_cur_elements(cache)-1);
    }

    return HAM_SUCCESS;
}



ham_status_t
cache_check_integrity(ham_cache_t *cache)
{
    ham_size_t elements=0;
    ham_page_t *head;

    /* count the cached pages */
    head=cache_get_totallist(cache);
    while (head) {
        elements++;
        head=page_get_next(head, PAGE_LIST_CACHED);
    }

    /* did we count the correct numbers? */
    if (cache_get_cur_elements(cache) != elements) {
        ham_trace(("cache's number of elements (%u) != actual number (%u)",
                cache_get_cur_elements(cache), elements));
        return (HAM_INTEGRITY_VIOLATED);
    }

    return HAM_SUCCESS;
}


/**
* @endcond
*/

>>>>>>> flash-bang-grenade
