 
I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x update doxygen documentation on the webpage

x update prebuilt libraries on the webpage (include boost)

x add Ger's freelist patch

x unittest: valgrind reports leaks in the test
    ==22694== 150 bytes in 5 blocks are definitely lost in loss record 1 of 6
    ==22694==    at 0x4C28B35: operator new(unsigned long)
    (vg_replace_malloc.c:261)
    ==22694==    by 0x575B058: std::string::_Rep::_S_create(unsigned long, unsigned
    long, std::allocator<char> const&) (in
    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.16)
    ==22694==    by 0x575B249: std::string::_M_mutate(unsigned long, unsigned long,
    unsigned long) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.16)
    ==22694==    by 0x575B3EB: std::string::_M_replace_safe(unsigned long, unsigned
    long, char const*, unsigned long) (in
    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.16)
    ==22694==    by 0x422671: LogEntry::LogEntry(unsigned long, unsigned long,
    unsigned int, unsigned short, char const*) (journal.cpp:46)
    ==22694==    by 0x42C809: JournalTest::iterateOverLogMultipleEntryTest()
    (journal.cpp:587)
    
x email from Jason: Great product as usual. 20.2 seems to have broken the .NET
    unit test "GetError" in DatabaseTest.cs. It ultimately calls 
    ham_get_error which causes an exception

x btree_read_key: calls db->get_extended_key, which should use an
    existing ByteArray to avoid memory allocations
    - no, cannot because the pointer is cached

x db_erase_txn: calls check_erase_conflict, which does a btree lookup.
    but the lookup then happens again when doing the final erase, or not?
    - no, everything is fine

x extend the FAQ and the tutorial
    x thread safety
    x rec.data scope

x extend the documentation with information about the new Transactions

x freelist: make sure that it allows to re-set bits that are already set
    and to delete bits that are already deleted (to make operations
    idempotent for recovery)
    x add tests

x look at Peter's mail - sometimes, ham_env_create_db returns
    HAM_INTERNAL_ERROR (only win32, C++ API, Windows 7)
    x replace HAM_INTERNAL_ERROR with asserts
    x OR use the error logger to write additional information

x a typical lessfs run has many many seeks - where do they come from?
    -> pread/pwrite was not checked correctly in configure.in

x Mark reported an error after kill -9 (with Txn, 2.0.2)
    i managed to reproduce this twice; a blob-page is corrupt
    x add instrumentation to Page::flush, Changeset::flush and Log::flush; 
            write to stdout
    x fsync's were missing; make flushing of changeset more robust
    x then try to reproduce once more and see if that page was (or was not)
        flushed
    sudo ./mklessfs /etc/lessfs.cfg
    sudo ./lessfs /etc/lessfs.cfg /home/chris/tmp/data/dir/ -f -d
    sudo dd bs=1024 if=/dev/sda of=/home/chris/tmp/data/dir/test.img
    sudo pkill -9 lessfs
    sudo sh check.sh

o support MS Visual Studio 2010

o identify a set of 3 testfiles (long running) and let them run in different
    configurations; track the times. There should be few enough tests to be
    able to compare the times manually!








o more fine-grained locking
    x cache
        x make sure it's perfectly abstracted
        x protect with mutex
    x extkey-cache
        x make sure it's perfectly abstracted
        x protect with mutex
    x log
        x make sure it's perfectly abstracted
        x protect with mutex
    x journal
        x make sure it's perfectly abstracted
        x protect with mutex
    x changeset
        x make sure it's perfectly abstracted
        x protect with mutex
    x device
        x make sure it's perfectly abstracted
        x protect with mutex
    o freelist
        x remove HAM_DAM_ENFORCE_PRE110_FORMAT
        x remove legacy code (1.x)
        x remove freelist_v2.cc
        o create c++ class
        o freelist class takes ownership of freelist_cache (from device)
        o protect with mutex
    o backend
        o replace with C++ class and inheritance
        o BtreeBackend does not require to store in little/big-endian!
            -- why not??
        o remove be_set_dirty, replace with be->_fun_flush()
        o btree has keydata1, keydata2 - why? better use DynamicArray?
        o improve abstraction
        o assert that the Database is locked
    o statistics
        o split into env/db/freelist
        o remove unused code
        o protect env and freelist with mutex
        o in db: assert that the db is locked
    o db
        o completely hide the local/remote implementation in the database
        o move more members from Database to the Implementation classes
        o improve abstraction
        o protect with mutex
    o env
        o completely hide the local/remote implementation in the Environment
        o move more members from Environment to the Implementation classes
        o improve abstraction
    o txn
        o convert to clean c++ code
        o protect with a mutex
        o when changing the transaction queue: assert that the env is locked
    o configuration/env-header-page
        o create configuration object
        o protect with mutex
    o file filters -- why? the filter list is not modified in the selected
        functions; but it needs to be documented that it has to be
        threadsafe, therefore verify that the AES filter *is* threadsafe
        o convert to C++ visitor pattern?
    o page
        o do we also need to lock pages?? or are they locked implicitly by
            adding them to the changeset? if yes then make sure that this is
            failsafe! and assert that there can be only one changeset at a
            time
        o changeset::contains is not thread safe
            only used in Cache::purge
	o the pages are only used in the btree (with one exception: header
            page); should the cache therefore be limited to btree functions?
            then purge and other stuff can also move to the btree level and
            everything gets simplified     

    o all other functions/modules: assert that the env-mutex is locked!

    o use read/write lock for Environment
    o introduce a new lock in the Database
    o the following functions lock the Environment for reading, but the
        Database for writing:
        o ham_insert
        o ham_find
        o ham_erase
        o ham_cursor_*
    o any others?
    o make sure that the cache does not flush pages that are currently locked
        by any Transaction

o blob_allocate: remove writev when writing header and blob body

o also remove locking from C# and Java APIs

o why do tests with 20 threads fail with oom when using mmap? the cache limits
    should still work

. look at ssb's clang output and try to integrate it into the build process

. need a way to graphically display performance metrics
    o output in a text file
        version/configuration/test-id
        each test is run in multiple threads
            performance-metrics based on time(), not real duration
            memory-metrics
            disk size
            same for berkeleydb
    o skript that generates a static html page from this file, 
        w/ graphs over the different versions

o implementation of hamsterdb should move into a namespace; otherwise
    there are conflicts if users have a C++ class called Database or
    Environment etc

o clean up the "close" functions
    o ham_close - move all functionality to Database::close
    o ham_env_close - move all functionality to Environment::close
    o ~Database: call close(), then simplify all code
    o ~Environment: call close(), then simplify all code
    o Cursor::close: currently (nearly) empty; merge with ~Cursor and
        Database::close_cursor()

o python API - update and integrate
    o rewrite with boost::python??
    o also add to win32 package

<<<<<<< Updated upstream
o continue with c++-ification of db.h/db.cc

o c++-ify the backend
    o replace with C++ class and inheritance
    o BtreeBackend does not require to store in little/big-endian!
    o remove be_set_dirty, replace with be->_fun_flush()
    o btree has keydata1, keydata2 - why? better use DynamicArray?
=======
>>>>>>> Stashed changes





o move flushing of transactions in background
    o new flag HAM_DISABLE_ASYNC_COMMITS
    o need new test: n threads; each thread inserts keys [i*n, i*(n+1))
    o make sure that each Database accesses its own pages; i.e. do not share
        blob pages between databases. Each database stores the address of the
        previously used blob page in order to reduce freelist access
    o when flushing and values are written to multiple databases: write them
        in parallel

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zur√ºckgeben?
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

o recovery: re-create pending transactions (if required)
    o needs a function to enumerate them

o c++-ify the transaction






o allow transactions in-memory

o allow transactions w/o journal

o allow transactions w/o recovery

o rename HAM_WRITE_THROUGH to HAM_ENABLE_FSYNC

o new node format:
    iiikkkkkkkkkrrrrrrrr

    iii: fixed size index (skip-list)
    kkk: keys
    rrr: records
    keys can have different compressions (bitmap, suppress null, ...)
    records are compressed; will be multiplied by BLOCKSIZE (32)
    each key consists of { char flag; short record_id; char data[1]; }
        where record_id is an offset into rrrrrrrrr
    keys are sorted lazily (i.e. inserted at the end and only sorted 
        when flushed to disk or when searched

. android port (needs new java api) in /contrib directory (it's on a separate
    branch)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. look for someone who can write a PHP or Perl or Ruby wrapper

. implement support for partial keys

. test with tcmalloc; if it works then also use it in the master branch, but
    make sure that memory consumption does not increase significantly

. there are a couple of areas where a btree cursor is uncoupled, just to 
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. hash-table.h: the foreach/remove_if/visitor pattern is clumsy. use 
    functor or class w/ operator() instead
. changeset: use a generic hash table for fast lookup (but leave list in place
    for everything else)
. cache: use a generic hash table

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. the whole c++ protocol should be c++-ified

. move the whole configuration (key sizes, parameters, page size, etc) into a 
    separate class which is instantiated by the env

. c++-ify the btree node representation; 
    o include duplicates as well! disentangle duplicates from blob-handling

. c++-ify the blob handling and split off the duplicates

. cleanup db.h/db.cc - move functions into Database or 
    DatabaseImplementationLocal namespace - but take care b/c these functions
    are also used by Cursor or other modules which don't necessarily have
    access to the Local stuff
    o db_get_key_count
    o db_alloc_page
    o db_fetch_page
    o db_insert_txn
    o db_erase_txn
    o db_find_txn
    o db_check_insert_conflicts
    o db_check_erase_conflicts
    o __increment_dupe_index

. c++-ify everything else

. device, page and os shold no longer return errors but throw exceptions

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE !!! XXXXXXXXXXXXXXXXXXXXXXXXXXXXX

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the blob, not
    to the log. the log will only contain the rid.
    o document this (and also the drawback - that an abort will lose the 
        blobs and they cannot be reused
    -> this affects all temporary ham_insert-transactions 
    (not sure if this should get high priority)

o hamsterdb.com
    x add twitter feed
    o API documentation: don't link to "modules" but to startup page, update
        with newest version
    o crupp.de: do a backup of the database
    . google +1 button
    . can we use something like Aller.font?

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation as a tar
    o the Changelog
    o the release notes (a template)
    o the output (xml) of the monster tests

. port to WinCE

o how can we extend the monster-tests to have reliable tests for transactions?

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created

o extkeys: don't use txn_id for the 'age', use lsn instead

o the DatabaseImplementation subclass is not neccessary; all subclasses
    can directly derive from Database. 

. allow use of transactions without a log/journal

. allow use of transactions for in-memory databases

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

o ham_get_count: could be atomically updated with every journal entry

o when flushing a changeset: sort by offset, use writev()

o add concurrency (on a high level)

o flush transactions in background

. have a flag to disable flushing of logfiles/journal files (or flush them 
    async.)

o continue as described in integrate-ham2.txt...

