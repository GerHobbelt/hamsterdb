 
I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x update doxygen documentation on the webpage

x update prebuilt libraries on the webpage (include boost)

x add Ger's freelist patch

o Mark reported an error after surprise-shutdown
    o with or without logging?
    o get access to the corrupt file
    o ...

o unittest: valgrind reports leaks in the test
    ==22694== 150 bytes in 5 blocks are definitely lost in loss record 1 of 6
    ==22694==    at 0x4C28B35: operator new(unsigned long)
    (vg_replace_malloc.c:261)
    ==22694==    by 0x575B058: std::string::_Rep::_S_create(unsigned long, unsigned
    long, std::allocator<char> const&) (in
    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.16)
    ==22694==    by 0x575B249: std::string::_M_mutate(unsigned long, unsigned long,
    unsigned long) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.16)
    ==22694==    by 0x575B3EB: std::string::_M_replace_safe(unsigned long, unsigned
    long, char const*, unsigned long) (in
    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.16)
    ==22694==    by 0x422671: LogEntry::LogEntry(unsigned long, unsigned long,
    unsigned int, unsigned short, char const*) (journal.cpp:46)
    ==22694==    by 0x42C809: JournalTest::iterateOverLogMultipleEntryTest()
    (journal.cpp:587)
    
o extend the FAQ and the tutorial
  - thread safety
  - rec.data scope

o extend the documentation

o look at ssb's clang output and try to integrate it into the build process

. need a way to graphically display performance metrics
    o output in a text file
        version/configuration/test-id
        each test is run in multiple threads
            performance-metrics based on time(), not real duration
            memory-metrics
            disk size
            same for berkeleydb
    o skript that generates a static html page from this file, 
        w/ graphs over the different versions

o email from Jason: Great product as usual. 20.2 seems to have broken the .NET
    unit test "GetError" in DatabaseTest.cs. It ultimately calls 
    ham_get_error which causes an exception

o why do tests with 20 threads fail with oom when using mmap? the cache limits
    should still work

x btree_read_key: calls db->get_extended_key, which should use an
    existing ByteArray to avoid memory allocations
    - no, cannot because the pointer is cached

x db_erase_txn: calls check_erase_conflict, which does a btree lookup.
    but the lookup then happens again when doing the final erase, or not?
    - no, everything is fine

o more fine-grained locking: lock ham_db_t handle for ham_insert, ham_find,
    ham_cursor_*, ham_erase

o also remove locking from C# and Java APIs

o implementation of hamsterdb should move into a namespace; otherwise
    there are conflicts if users have a C++ class called Database or
    Environment etc

o clean up the "close" functions
    o ham_close - move all functionality to Database::close
    o ham_env_close - move all functionality to Environment::close
    o ~Database: call close(), then simplify all code
    o ~Environment: call close(), then simplify all code
    o Cursor::close: currently (nearly) empty; merge with ~Cursor and
        Database::close_cursor()

o python API - update and integrate
    o rewrite with boost::python??
    o also add to win32 package

o continue with c++-ification of db.h/db.cc

o c++-ify the backend
    o replace with C++ class and inheritance
    o BtreeBackend does not require to store in little/big-endian!
    o remove be_set_dirty, replace with be->_fun_flush()
    o btree has keydata1, keydata2 - why? better use DynamicArray?





o move flushing of transactions in background
    o new flag HAM_DISABLE_ASYNC_COMMITS
    o need new test: n threads; each thread inserts keys [i*n, i*(n+1))

o continue with c++-ification of the environment - need to split into
    local and remote (same as for Database class)

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurÃ¼ckgeben?
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

o recovery: re-create pending transactions (if required)
    o needs a function to enumerate them

o c++-ify the transaction






o allow transactions in-memory

o allow transactions w/o journal

o allow transactions w/o recovery

o rename HAM_WRITE_THROUGH to HAM_ENABLE_FSYNC

o new node format:
    iiikkkkkkkkkrrrrrrrr

    iii: fixed size index (skip-list)
    kkk: keys
    rrr: records
    keys can have different compressions (bitmap, suppress null, ...)
    records are compressed; will be multiplied by BLOCKSIZE (32)
    each key consists of { char flag; short record_id; char data[1]; }
        where record_id is an offset into rrrrrrrrr
    keys are sorted lazily (i.e. inserted at the end and only sorted 
        when flushed to disk or when searched

. android port (needs new java api) in /contrib directory (it's on a separate
    branch)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. look for someone who can write a PHP or Perl or Ruby wrapper

. implement support for partial keys

. test with tcmalloc; if it works then also use it in the master branch, but
    make sure that memory consumption does not increase significantly

. there are a couple of areas where a btree cursor is uncoupled, just to 
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. hash-table.h: the foreach/remove_if/visitor pattern is clumsy. use 
    functor or class w/ operator() instead
. changeset: use a generic hash table for fast lookup (but leave list in place
    for everything else)
. cache: use a generic hash table

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. the whole c++ protocol should be c++-ified

. move the whole configuration (key sizes, parameters, page size, etc) into a 
    separate class which is instantiated by the env

. c++-ify the btree node representation; 
    o include duplicates as well! disentangle duplicates from blob-handling

. c++-ify the blob handling and split off the duplicates

. cleanup db.h/db.cc - move functions into Database or 
    DatabaseImplementationLocal namespace - but take care b/c these functions
    are also used by Cursor or other modules which don't necessarily have
    access to the Local stuff
    o db_get_key_count
    o db_alloc_page
    o db_fetch_page
    o db_insert_txn
    o db_erase_txn
    o db_find_txn
    o db_check_insert_conflicts
    o db_check_erase_conflicts
    o __increment_dupe_index

. c++-ify everything else

. device, page and os shold no longer return errors but throw exceptions

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE !!! XXXXXXXXXXXXXXXXXXXXXXXXXXXXX

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the blob, not
    to the log. the log will only contain the rid.
    o document this (and also the drawback - that an abort will lose the 
        blobs and they cannot be reused
    -> this affects all temporary ham_insert-transactions 
    (not sure if this should get high priority)

o hamsterdb.com
    x add twitter feed
    o API documentation: don't link to "modules" but to startup page, update
        with newest version
    o crupp.de: do a backup of the database
    . google +1 button
    . can we use something like Aller.font?

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation as a tar
    o the Changelog
    o the release notes (a template)
    o the output (xml) of the monster tests

. port to WinCE

o how can we extend the monster-tests to have reliable tests for transactions?

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created

o extkeys: don't use txn_id for the 'age', use lsn instead

o the DatabaseImplementation subclass is not neccessary; all subclasses
    can directly derive from Database. 

. allow use of transactions without a log/journal

. allow use of transactions for in-memory databases

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

o ham_get_count: could be atomically updated with every journal entry

o when flushing a changeset: sort by offset, use writev()

o add concurrency (on a high level)

o flush transactions in background

. have a flag to disable flushing of logfiles/journal files (or flush them 
    async.)

o continue as described in integrate-ham2.txt...

